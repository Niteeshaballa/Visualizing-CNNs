{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Dream with Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import inception_v3\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pre-trained Inception\n",
    "#disabling training operations\n",
    "K.set_learning_phase(0)\n",
    "model = inception_v3.InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, None, None, 3 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, None, None, 3 96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, None, None, 3 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, None, None, 3 9216        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, None, None, 3 96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, None, None, 3 0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, None, None, 6 18432       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, None, None, 6 192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, None, None, 6 0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 6 0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, None, None, 8 5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, None, None, 8 240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, None, None, 8 0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, None, None, 1 138240      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, None, None, 1 576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, None, None, 1 0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, None, None, 1 0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, None, None, 6 192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, None, None, 6 0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, None, None, 9 55296       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, None, None, 4 144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, None, None, 9 288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, None, None, 4 0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, None, None, 9 0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, None, None, 1 0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, None, None, 6 76800       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, None, None, 9 82944       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, None, None, 6 192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, None, None, 6 192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, None, None, 9 288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, None, None, 3 96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, None, None, 6 0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, None, None, 6 0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, None, None, 9 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, None, None, 3 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_100[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, None, None, 6 192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, None, None, 6 0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, None, None, 9 55296       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, None, None, 4 144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, None, None, 9 288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, None, None, 4 0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, None, None, 9 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, None, None, 6 76800       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, None, None, 9 82944       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, None, None, 6 192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, None, None, 6 192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, None, None, 9 288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, None, None, 6 192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, None, None, 6 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, None, None, 6 0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, None, None, 9 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, None, None, 6 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_107[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, None, None, 6 192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, None, None, 6 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, None, None, 9 55296       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, None, None, 4 144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, None, None, 9 288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, None, None, 4 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, None, None, 9 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, None, None, 6 76800       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, None, None, 9 82944       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, None, None, 6 192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, None, None, 6 192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, None, None, 9 288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, None, None, 6 192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, None, None, 6 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, None, None, 6 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, None, None, 9 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, None, None, 6 0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_114[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, None, None, 6 192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, None, None, 6 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, None, None, 9 55296       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, None, None, 9 288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, None, None, 9 0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, None, None, 9 82944       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, None, None, 3 1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, None, None, 9 288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, None, None, 3 0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, None, None, 9 0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, None, None, 1 384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, None, None, 1 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, None, None, 1 114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, None, None, 1 384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, None, None, 1 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, None, None, 1 114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, None, None, 1 384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, None, None, 1 384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, None, None, 1 0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, None, None, 1 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, None, None, 1 114688      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, None, None, 1 114688      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, None, None, 1 384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, None, None, 1 384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, None, None, 1 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, None, None, 1 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, None, None, 1 172032      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, None, None, 1 172032      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, None, None, 1 576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, None, None, 1 576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, None, None, 1 576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, None, None, 1 576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, None, None, 1 0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, None, None, 1 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, None, None, 1 0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, None, None, 1 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, None, None, 1 480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, None, None, 1 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, None, None, 1 179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, None, None, 1 480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, None, None, 1 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, None, None, 1 179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, None, None, 1 480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, None, None, 1 480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, None, None, 1 0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, None, None, 1 0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, None, None, 1 179200      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, None, None, 1 179200      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, None, None, 1 480         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, None, None, 1 480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, None, None, 1 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, None, None, 1 0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, None, None, 1 215040      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, None, None, 1 215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, None, None, 1 576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, None, None, 1 576         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, None, None, 1 576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, None, None, 1 576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, None, None, 1 0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, None, None, 1 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, None, None, 1 0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, None, None, 1 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_135[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, None, None, 1 480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, None, None, 1 0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, None, None, 1 179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, None, None, 1 480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, None, None, 1 0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, None, None, 1 179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, None, None, 1 480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, None, None, 1 480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, None, None, 1 0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, None, None, 1 0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, None, None, 1 179200      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, None, None, 1 179200      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, None, None, 1 480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, None, None, 1 480         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, None, None, 1 0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, None, None, 1 0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, None, None, 1 215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, None, None, 1 215040      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, None, None, 1 576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, None, None, 1 576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, None, None, 1 576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, None, None, 1 576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, None, None, 1 0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, None, None, 1 0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, None, None, 1 0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, None, None, 1 0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "                                                                 activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, None, None, 1 576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, None, None, 1 0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, None, None, 1 258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, None, None, 1 576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, None, None, 1 0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, None, None, 1 258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, None, None, 1 576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, None, None, 1 576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, None, None, 1 0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, None, None, 1 0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, None, None, 1 258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, None, None, 1 258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, None, None, 1 576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, None, None, 1 576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, None, None, 1 0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, None, None, 1 0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, None, None, 1 258048      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, None, None, 1 258048      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, None, None, 1 576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, None, None, 1 576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, None, None, 1 576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, None, None, 1 576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, None, None, 1 0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, None, None, 1 0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, None, None, 1 0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, None, None, 1 0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_155[0][0]             \n",
      "                                                                 activation_158[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, None, None, 1 576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, None, None, 1 0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, None, None, 1 258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, None, None, 1 576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, None, None, 1 0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, None, None, 1 258048      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, None, None, 1 576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, None, None, 1 576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, None, None, 1 0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, None, None, 1 0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, None, None, 3 552960      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, None, None, 1 331776      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, None, None, 3 960         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, None, None, 1 576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, None, None, 3 0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, None, None, 1 0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_166[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, None, None, 4 1344        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, None, None, 4 0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, None, None, 3 1548288     activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, None, None, 3 1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, None, None, 3 1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, None, None, 3 0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, None, None, 3 0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, None, None, 3 442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, None, None, 3 442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, None, None, 3 442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, None, None, 3 442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, None, None, 3 1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, None, None, 3 1152        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, None, None, 3 1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, None, None, 3 1152        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, None, None, 3 960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, None, None, 3 0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, None, None, 3 0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, None, None, 3 0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, None, None, 3 0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, None, None, 1 576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, None, None, 3 0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, None, None, 7 0           activation_177[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, None, None, 1 0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_171[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, None, None, 4 1344        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, None, None, 4 0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, None, None, 3 1548288     activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, None, None, 3 1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, None, None, 3 1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, None, None, 3 0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, None, None, 3 0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, None, None, 3 442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, None, None, 3 442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, None, None, 3 442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, None, None, 3 442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, None, None, 3 1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, None, None, 3 1152        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, None, None, 3 1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, None, None, 3 1152        conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, None, None, 3 960         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, None, None, 3 0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, None, None, 3 0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, None, None, 3 0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, None, None, 3 0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, None, None, 1 576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, None, None, 3 0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_182[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, None, None, 7 0           activation_186[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, None, None, 1 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_180[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_188[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict mapping layernames to coefficients quantifying how much the layer's activation contributes to the loss\n",
    "layer_contributions = {'mixed2':0.2, 'mixed3':3., 'mixed4':2., 'mixed5':1.5,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_2': <keras.engine.input_layer.InputLayer at 0x1dd6754db38>,\n",
       " 'conv2d_95': <keras.layers.convolutional.Conv2D at 0x1dd6754de10>,\n",
       " 'batch_normalization_95': <keras.layers.normalization.BatchNormalization at 0x1dd6755f048>,\n",
       " 'activation_95': <keras.layers.core.Activation at 0x1dd6755fd30>,\n",
       " 'conv2d_96': <keras.layers.convolutional.Conv2D at 0x1dd67321d30>,\n",
       " 'batch_normalization_96': <keras.layers.normalization.BatchNormalization at 0x1dd6721b940>,\n",
       " 'activation_96': <keras.layers.core.Activation at 0x1dd6728dc50>,\n",
       " 'conv2d_97': <keras.layers.convolutional.Conv2D at 0x1dd67424c88>,\n",
       " 'batch_normalization_97': <keras.layers.normalization.BatchNormalization at 0x1dd6191eeb8>,\n",
       " 'activation_97': <keras.layers.core.Activation at 0x1dd618ec1d0>,\n",
       " 'max_pooling2d_5': <keras.layers.pooling.MaxPooling2D at 0x1dd6190d550>,\n",
       " 'conv2d_98': <keras.layers.convolutional.Conv2D at 0x1dd61a225c0>,\n",
       " 'batch_normalization_98': <keras.layers.normalization.BatchNormalization at 0x1dd619e4be0>,\n",
       " 'activation_98': <keras.layers.core.Activation at 0x1dd619e49b0>,\n",
       " 'conv2d_99': <keras.layers.convolutional.Conv2D at 0x1dd61a28c18>,\n",
       " 'batch_normalization_99': <keras.layers.normalization.BatchNormalization at 0x1dd61ae1748>,\n",
       " 'activation_99': <keras.layers.core.Activation at 0x1dd61a702e8>,\n",
       " 'max_pooling2d_6': <keras.layers.pooling.MaxPooling2D at 0x1dd61b03dd8>,\n",
       " 'conv2d_103': <keras.layers.convolutional.Conv2D at 0x1dd63cb0160>,\n",
       " 'batch_normalization_103': <keras.layers.normalization.BatchNormalization at 0x1dd63d68ac8>,\n",
       " 'activation_103': <keras.layers.core.Activation at 0x1dd63d9db70>,\n",
       " 'conv2d_101': <keras.layers.convolutional.Conv2D at 0x1dd63c400b8>,\n",
       " 'conv2d_104': <keras.layers.convolutional.Conv2D at 0x1dd63d886a0>,\n",
       " 'batch_normalization_101': <keras.layers.normalization.BatchNormalization at 0x1dd63bbd668>,\n",
       " 'batch_normalization_104': <keras.layers.normalization.BatchNormalization at 0x1dd63e75dd8>,\n",
       " 'activation_101': <keras.layers.core.Activation at 0x1dd63c40f28>,\n",
       " 'activation_104': <keras.layers.core.Activation at 0x1dd63ebcac8>,\n",
       " 'average_pooling2d_10': <keras.layers.pooling.AveragePooling2D at 0x1dd63f946a0>,\n",
       " 'conv2d_100': <keras.layers.convolutional.Conv2D at 0x1dd61bbceb8>,\n",
       " 'conv2d_102': <keras.layers.convolutional.Conv2D at 0x1dd63d448d0>,\n",
       " 'conv2d_105': <keras.layers.convolutional.Conv2D at 0x1dd63e5e588>,\n",
       " 'conv2d_106': <keras.layers.convolutional.Conv2D at 0x1dd63f0b978>,\n",
       " 'batch_normalization_100': <keras.layers.normalization.BatchNormalization at 0x1dd61b8bd68>,\n",
       " 'batch_normalization_102': <keras.layers.normalization.BatchNormalization at 0x1dd63c92860>,\n",
       " 'batch_normalization_105': <keras.layers.normalization.BatchNormalization at 0x1dd63f0b358>,\n",
       " 'batch_normalization_106': <keras.layers.normalization.BatchNormalization at 0x1dd640256d8>,\n",
       " 'activation_100': <keras.layers.core.Activation at 0x1dd61b8bdd8>,\n",
       " 'activation_102': <keras.layers.core.Activation at 0x1dd63d1afd0>,\n",
       " 'activation_105': <keras.layers.core.Activation at 0x1dd63f356d8>,\n",
       " 'activation_106': <keras.layers.core.Activation at 0x1dd64025898>,\n",
       " 'mixed0': <keras.layers.merge.Concatenate at 0x1dd64080f28>,\n",
       " 'conv2d_110': <keras.layers.convolutional.Conv2D at 0x1dd6431bf60>,\n",
       " 'batch_normalization_110': <keras.layers.normalization.BatchNormalization at 0x1dd6436db00>,\n",
       " 'activation_110': <keras.layers.core.Activation at 0x1dd643a0d30>,\n",
       " 'conv2d_108': <keras.layers.convolutional.Conv2D at 0x1dd64141ac8>,\n",
       " 'conv2d_111': <keras.layers.convolutional.Conv2D at 0x1dd644fb4a8>,\n",
       " 'batch_normalization_108': <keras.layers.normalization.BatchNormalization at 0x1dd641f1358>,\n",
       " 'batch_normalization_111': <keras.layers.normalization.BatchNormalization at 0x1dd644480b8>,\n",
       " 'activation_108': <keras.layers.core.Activation at 0x1dd64214f98>,\n",
       " 'activation_111': <keras.layers.core.Activation at 0x1dd644cfb38>,\n",
       " 'average_pooling2d_11': <keras.layers.pooling.AveragePooling2D at 0x1dd64599ac8>,\n",
       " 'conv2d_107': <keras.layers.convolutional.Conv2D at 0x1dd640b5f98>,\n",
       " 'conv2d_109': <keras.layers.convolutional.Conv2D at 0x1dd6423acf8>,\n",
       " 'conv2d_112': <keras.layers.convolutional.Conv2D at 0x1dd644664e0>,\n",
       " 'conv2d_113': <keras.layers.convolutional.Conv2D at 0x1dd6468acf8>,\n",
       " 'batch_normalization_107': <keras.layers.normalization.BatchNormalization at 0x1dd6416c828>,\n",
       " 'batch_normalization_109': <keras.layers.normalization.BatchNormalization at 0x1dd642945f8>,\n",
       " 'batch_normalization_112': <keras.layers.normalization.BatchNormalization at 0x1dd6450db38>,\n",
       " 'batch_normalization_113': <keras.layers.normalization.BatchNormalization at 0x1dd64655ac8>,\n",
       " 'activation_107': <keras.layers.core.Activation at 0x1dd640e9f60>,\n",
       " 'activation_109': <keras.layers.core.Activation at 0x1dd64313588>,\n",
       " 'activation_112': <keras.layers.core.Activation at 0x1dd64554dd8>,\n",
       " 'activation_113': <keras.layers.core.Activation at 0x1dd6467a6a0>,\n",
       " 'mixed1': <keras.layers.merge.Concatenate at 0x1dd6468ada0>,\n",
       " 'conv2d_117': <keras.layers.convolutional.Conv2D at 0x1dd6490aeb8>,\n",
       " 'batch_normalization_117': <keras.layers.normalization.BatchNormalization at 0x1dd64990550>,\n",
       " 'activation_117': <keras.layers.core.Activation at 0x1dd64a3fda0>,\n",
       " 'conv2d_115': <keras.layers.convolutional.Conv2D at 0x1dd647a4198>,\n",
       " 'conv2d_118': <keras.layers.convolutional.Conv2D at 0x1dd64a14c50>,\n",
       " 'batch_normalization_115': <keras.layers.normalization.BatchNormalization at 0x1dd647ebf28>,\n",
       " 'batch_normalization_118': <keras.layers.normalization.BatchNormalization at 0x1dd64a9ff98>,\n",
       " 'activation_115': <keras.layers.core.Activation at 0x1dd647d8eb8>,\n",
       " 'activation_118': <keras.layers.core.Activation at 0x1dd64aedc88>,\n",
       " 'average_pooling2d_12': <keras.layers.pooling.AveragePooling2D at 0x1dd64b654e0>,\n",
       " 'conv2d_114': <keras.layers.convolutional.Conv2D at 0x1dd646fbc88>,\n",
       " 'conv2d_116': <keras.layers.convolutional.Conv2D at 0x1dd6484e4a8>,\n",
       " 'conv2d_119': <keras.layers.convolutional.Conv2D at 0x1dd64af5c88>,\n",
       " 'conv2d_120': <keras.layers.convolutional.Conv2D at 0x1dd64cae588>,\n",
       " 'batch_normalization_114': <keras.layers.normalization.BatchNormalization at 0x1dd64753f98>,\n",
       " 'batch_normalization_116': <keras.layers.normalization.BatchNormalization at 0x1dd648b1d30>,\n",
       " 'batch_normalization_119': <keras.layers.normalization.BatchNormalization at 0x1dd64b4a5f8>,\n",
       " 'batch_normalization_120': <keras.layers.normalization.BatchNormalization at 0x1dd64c41320>,\n",
       " 'activation_114': <keras.layers.core.Activation at 0x1dd6470fa20>,\n",
       " 'activation_116': <keras.layers.core.Activation at 0x1dd6492e780>,\n",
       " 'activation_119': <keras.layers.core.Activation at 0x1dd64bd1b38>,\n",
       " 'activation_120': <keras.layers.core.Activation at 0x1dd64c9c128>,\n",
       " 'mixed2': <keras.layers.merge.Concatenate at 0x1dd64caebe0>,\n",
       " 'conv2d_122': <keras.layers.convolutional.Conv2D at 0x1dd64d7c828>,\n",
       " 'batch_normalization_122': <keras.layers.normalization.BatchNormalization at 0x1dd64e85860>,\n",
       " 'activation_122': <keras.layers.core.Activation at 0x1dd64dfd080>,\n",
       " 'conv2d_123': <keras.layers.convolutional.Conv2D at 0x1dd64ea6eb8>,\n",
       " 'batch_normalization_123': <keras.layers.normalization.BatchNormalization at 0x1dd64f62c50>,\n",
       " 'activation_123': <keras.layers.core.Activation at 0x1dd64eed4e0>,\n",
       " 'conv2d_121': <keras.layers.convolutional.Conv2D at 0x1dd64d35518>,\n",
       " 'conv2d_124': <keras.layers.convolutional.Conv2D at 0x1dd64f83f60>,\n",
       " 'batch_normalization_121': <keras.layers.normalization.BatchNormalization at 0x1dd64d1ad30>,\n",
       " 'batch_normalization_124': <keras.layers.normalization.BatchNormalization at 0x1dd64fb5e48>,\n",
       " 'activation_121': <keras.layers.core.Activation at 0x1dd64ceebe0>,\n",
       " 'activation_124': <keras.layers.core.Activation at 0x1dd6500de48>,\n",
       " 'max_pooling2d_7': <keras.layers.pooling.MaxPooling2D at 0x1dd65030eb8>,\n",
       " 'mixed3': <keras.layers.merge.Concatenate at 0x1dd650e8a20>,\n",
       " 'conv2d_129': <keras.layers.convolutional.Conv2D at 0x1dd67153f98>,\n",
       " 'batch_normalization_129': <keras.layers.normalization.BatchNormalization at 0x1dd674819e8>,\n",
       " 'activation_129': <keras.layers.core.Activation at 0x1dd671ae278>,\n",
       " 'conv2d_130': <keras.layers.convolutional.Conv2D at 0x1dd671779e8>,\n",
       " 'batch_normalization_130': <keras.layers.normalization.BatchNormalization at 0x1dd654e6c88>,\n",
       " 'activation_130': <keras.layers.core.Activation at 0x1dd65571908>,\n",
       " 'conv2d_126': <keras.layers.convolutional.Conv2D at 0x1dd651f9be0>,\n",
       " 'conv2d_131': <keras.layers.convolutional.Conv2D at 0x1dd654ffbe0>,\n",
       " 'batch_normalization_126': <keras.layers.normalization.BatchNormalization at 0x1dd6516dc50>,\n",
       " 'batch_normalization_131': <keras.layers.normalization.BatchNormalization at 0x1dd655c7e10>,\n",
       " 'activation_126': <keras.layers.core.Activation at 0x1dd651f9da0>,\n",
       " 'activation_131': <keras.layers.core.Activation at 0x1dd65640630>,\n",
       " 'conv2d_127': <keras.layers.convolutional.Conv2D at 0x1dd651c1f60>,\n",
       " 'conv2d_132': <keras.layers.convolutional.Conv2D at 0x1dd65677e80>,\n",
       " 'batch_normalization_127': <keras.layers.normalization.BatchNormalization at 0x1dd651e9c50>,\n",
       " 'batch_normalization_132': <keras.layers.normalization.BatchNormalization at 0x1dd656a0a58>,\n",
       " 'activation_127': <keras.layers.core.Activation at 0x1dd652dae48>,\n",
       " 'activation_132': <keras.layers.core.Activation at 0x1dd65729fd0>,\n",
       " 'average_pooling2d_13': <keras.layers.pooling.AveragePooling2D at 0x1dd657f3b00>,\n",
       " 'conv2d_125': <keras.layers.convolutional.Conv2D at 0x1dd6510f400>,\n",
       " 'conv2d_128': <keras.layers.convolutional.Conv2D at 0x1dd65266e10>,\n",
       " 'conv2d_133': <keras.layers.convolutional.Conv2D at 0x1dd656f30f0>,\n",
       " 'conv2d_134': <keras.layers.convolutional.Conv2D at 0x1dd65911630>,\n",
       " 'batch_normalization_125': <keras.layers.normalization.BatchNormalization at 0x1dd65117fd0>,\n",
       " 'batch_normalization_128': <keras.layers.normalization.BatchNormalization at 0x1dd6530ecf8>,\n",
       " 'batch_normalization_133': <keras.layers.normalization.BatchNormalization at 0x1dd65776ac8>,\n",
       " 'batch_normalization_134': <keras.layers.normalization.BatchNormalization at 0x1dd658717b8>,\n",
       " 'activation_125': <keras.layers.core.Activation at 0x1dd650ab898>,\n",
       " 'activation_128': <keras.layers.core.Activation at 0x1dd6535b0b8>,\n",
       " 'activation_133': <keras.layers.core.Activation at 0x1dd657addd8>,\n",
       " 'activation_134': <keras.layers.core.Activation at 0x1dd658d0390>,\n",
       " 'mixed4': <keras.layers.merge.Concatenate at 0x1dd658e4e80>,\n",
       " 'conv2d_139': <keras.layers.convolutional.Conv2D at 0x1dd65c1cd30>,\n",
       " 'batch_normalization_139': <keras.layers.normalization.BatchNormalization at 0x1dd65cad3c8>,\n",
       " 'activation_139': <keras.layers.core.Activation at 0x1dd65d17f60>,\n",
       " 'conv2d_140': <keras.layers.convolutional.Conv2D at 0x1dd65d4cdd8>,\n",
       " 'batch_normalization_140': <keras.layers.normalization.BatchNormalization at 0x1dd65e18d68>,\n",
       " 'activation_140': <keras.layers.core.Activation at 0x1dd65dbb780>,\n",
       " 'conv2d_136': <keras.layers.convolutional.Conv2D at 0x1dd659abe10>,\n",
       " 'conv2d_141': <keras.layers.convolutional.Conv2D at 0x1dd65cdc978>,\n",
       " 'batch_normalization_136': <keras.layers.normalization.BatchNormalization at 0x1dd65a82f98>,\n",
       " 'batch_normalization_141': <keras.layers.normalization.BatchNormalization at 0x1dd65e5fcc0>,\n",
       " 'activation_136': <keras.layers.core.Activation at 0x1dd65ab3f28>,\n",
       " 'activation_141': <keras.layers.core.Activation at 0x1dd65eaca90>,\n",
       " 'conv2d_137': <keras.layers.convolutional.Conv2D at 0x1dd65addd68>,\n",
       " 'conv2d_142': <keras.layers.convolutional.Conv2D at 0x1dd65f440b8>,\n",
       " 'batch_normalization_137': <keras.layers.normalization.BatchNormalization at 0x1dd65b254a8>,\n",
       " 'batch_normalization_142': <keras.layers.normalization.BatchNormalization at 0x1dd65ffe860>,\n",
       " 'activation_137': <keras.layers.core.Activation at 0x1dd65b8fef0>,\n",
       " 'activation_142': <keras.layers.core.Activation at 0x1dd65f88e10>,\n",
       " 'average_pooling2d_14': <keras.layers.pooling.AveragePooling2D at 0x1dd66102e80>,\n",
       " 'conv2d_135': <keras.layers.convolutional.Conv2D at 0x1dd659d7a90>,\n",
       " 'conv2d_138': <keras.layers.convolutional.Conv2D at 0x1dd65b5cdd8>,\n",
       " 'conv2d_143': <keras.layers.convolutional.Conv2D at 0x1dd66021eb8>,\n",
       " 'conv2d_144': <keras.layers.convolutional.Conv2D at 0x1dd66148d68>,\n",
       " 'batch_normalization_135': <keras.layers.normalization.BatchNormalization at 0x1dd65917e80>,\n",
       " 'batch_normalization_138': <keras.layers.normalization.BatchNormalization at 0x1dd65c39da0>,\n",
       " 'batch_normalization_143': <keras.layers.normalization.BatchNormalization at 0x1dd660cdbe0>,\n",
       " 'batch_normalization_144': <keras.layers.normalization.BatchNormalization at 0x1dd6615dba8>,\n",
       " 'activation_135': <keras.layers.core.Activation at 0x1dd65951208>,\n",
       " 'activation_138': <keras.layers.core.Activation at 0x1dd65c5f978>,\n",
       " 'activation_143': <keras.layers.core.Activation at 0x1dd660a9f60>,\n",
       " 'activation_144': <keras.layers.core.Activation at 0x1dd661a9d30>,\n",
       " 'mixed5': <keras.layers.merge.Concatenate at 0x1dd661b2ef0>,\n",
       " 'conv2d_149': <keras.layers.convolutional.Conv2D at 0x1dd66512f98>,\n",
       " 'batch_normalization_149': <keras.layers.normalization.BatchNormalization at 0x1dd66648fd0>,\n",
       " 'activation_149': <keras.layers.core.Activation at 0x1dd66597ef0>,\n",
       " 'conv2d_150': <keras.layers.convolutional.Conv2D at 0x1dd665afe10>,\n",
       " 'batch_normalization_150': <keras.layers.normalization.BatchNormalization at 0x1dd666a6be0>,\n",
       " 'activation_150': <keras.layers.core.Activation at 0x1dd66691550>,\n",
       " 'conv2d_146': <keras.layers.convolutional.Conv2D at 0x1dd662d0da0>,\n",
       " 'conv2d_151': <keras.layers.convolutional.Conv2D at 0x1dd666fce80>,\n",
       " 'batch_normalization_146': <keras.layers.normalization.BatchNormalization at 0x1dd66382e48>,\n",
       " 'batch_normalization_151': <keras.layers.normalization.BatchNormalization at 0x1dd6674e780>,\n",
       " 'activation_146': <keras.layers.core.Activation at 0x1dd662fe978>,\n",
       " 'activation_151': <keras.layers.core.Activation at 0x1dd66781b38>,\n",
       " 'conv2d_147': <keras.layers.convolutional.Conv2D at 0x1dd66310828>,\n",
       " 'conv2d_152': <keras.layers.convolutional.Conv2D at 0x1dd667c7ac8>,\n",
       " 'batch_normalization_147': <keras.layers.normalization.BatchNormalization at 0x1dd664627f0>,\n",
       " 'batch_normalization_152': <keras.layers.normalization.BatchNormalization at 0x1dd668e35c0>,\n",
       " 'activation_147': <keras.layers.core.Activation at 0x1dd663f0320>,\n",
       " 'activation_152': <keras.layers.core.Activation at 0x1dd668b5e48>,\n",
       " 'average_pooling2d_15': <keras.layers.pooling.AveragePooling2D at 0x1dd675ecf60>,\n",
       " 'conv2d_145': <keras.layers.convolutional.Conv2D at 0x1dd6627fd68>,\n",
       " 'conv2d_148': <keras.layers.convolutional.Conv2D at 0x1dd6648ae80>,\n",
       " 'conv2d_153': <keras.layers.convolutional.Conv2D at 0x1dd66844b00>,\n",
       " 'conv2d_154': <keras.layers.convolutional.Conv2D at 0x1dd78be59e8>,\n",
       " 'batch_normalization_145': <keras.layers.normalization.BatchNormalization at 0x1dd66221320>,\n",
       " 'batch_normalization_148': <keras.layers.normalization.BatchNormalization at 0x1dd664b86a0>,\n",
       " 'batch_normalization_153': <keras.layers.normalization.BatchNormalization at 0x1dd668f4c50>,\n",
       " 'batch_normalization_154': <keras.layers.normalization.BatchNormalization at 0x1dd78b73c50>,\n",
       " 'activation_145': <keras.layers.core.Activation at 0x1dd6615dc88>,\n",
       " 'activation_148': <keras.layers.core.Activation at 0x1dd665342b0>,\n",
       " 'activation_153': <keras.layers.core.Activation at 0x1dd66922da0>,\n",
       " 'activation_154': <keras.layers.core.Activation at 0x1dd78bbcc18>,\n",
       " 'mixed6': <keras.layers.merge.Concatenate at 0x1dd78c3ee80>,\n",
       " 'conv2d_159': <keras.layers.convolutional.Conv2D at 0x1dd78f46ef0>,\n",
       " 'batch_normalization_159': <keras.layers.normalization.BatchNormalization at 0x1dd78fcda90>,\n",
       " 'activation_159': <keras.layers.core.Activation at 0x1dd79074dd8>,\n",
       " 'conv2d_160': <keras.layers.convolutional.Conv2D at 0x1dd79052ac8>,\n",
       " 'batch_normalization_160': <keras.layers.normalization.BatchNormalization at 0x1dd790a5f98>,\n",
       " 'activation_160': <keras.layers.core.Activation at 0x1dd790bce10>,\n",
       " 'conv2d_156': <keras.layers.convolutional.Conv2D at 0x1dd78cede80>,\n",
       " 'conv2d_161': <keras.layers.convolutional.Conv2D at 0x1dd79101ef0>,\n",
       " 'batch_normalization_156': <keras.layers.normalization.BatchNormalization at 0x1dd78d4ae48>,\n",
       " 'batch_normalization_161': <keras.layers.normalization.BatchNormalization at 0x1dd79185358>,\n",
       " 'activation_156': <keras.layers.core.Activation at 0x1dd78d16748>,\n",
       " 'activation_161': <keras.layers.core.Activation at 0x1dd791dcf60>,\n",
       " 'conv2d_157': <keras.layers.convolutional.Conv2D at 0x1dd78d336d8>,\n",
       " 'conv2d_162': <keras.layers.convolutional.Conv2D at 0x1dd79231e80>,\n",
       " 'batch_normalization_157': <keras.layers.normalization.BatchNormalization at 0x1dd78ead080>,\n",
       " 'batch_normalization_162': <keras.layers.normalization.BatchNormalization at 0x1dd7925ff60>,\n",
       " 'activation_157': <keras.layers.core.Activation at 0x1dd78e81dd8>,\n",
       " 'activation_162': <keras.layers.core.Activation at 0x1dd79291ba8>,\n",
       " 'average_pooling2d_16': <keras.layers.pooling.AveragePooling2D at 0x1dd793b49e8>,\n",
       " 'conv2d_155': <keras.layers.convolutional.Conv2D at 0x1dd78cc0ef0>,\n",
       " 'conv2d_158': <keras.layers.convolutional.Conv2D at 0x1dd78e0e668>,\n",
       " 'conv2d_163': <keras.layers.convolutional.Conv2D at 0x1dd792dc8d0>,\n",
       " 'conv2d_164': <keras.layers.convolutional.Conv2D at 0x1dd794a3b70>,\n",
       " 'batch_normalization_155': <keras.layers.normalization.BatchNormalization at 0x1dd78c3e710>,\n",
       " 'batch_normalization_158': <keras.layers.normalization.BatchNormalization at 0x1dd78ebfef0>,\n",
       " 'batch_normalization_163': <keras.layers.normalization.BatchNormalization at 0x1dd79370b70>,\n",
       " 'batch_normalization_164': <keras.layers.normalization.BatchNormalization at 0x1dd7946beb8>,\n",
       " 'activation_155': <keras.layers.core.Activation at 0x1dd78c94f28>,\n",
       " 'activation_158': <keras.layers.core.Activation at 0x1dd78f8b5f8>,\n",
       " 'activation_163': <keras.layers.core.Activation at 0x1dd7933c160>,\n",
       " 'activation_164': <keras.layers.core.Activation at 0x1dd794a3cf8>,\n",
       " 'mixed7': <keras.layers.merge.Concatenate at 0x1dd795a6940>,\n",
       " 'conv2d_167': <keras.layers.convolutional.Conv2D at 0x1dd79644e48>,\n",
       " 'batch_normalization_167': <keras.layers.normalization.BatchNormalization at 0x1dd796facc0>,\n",
       " 'activation_167': <keras.layers.core.Activation at 0x1dd796cc780>,\n",
       " 'conv2d_168': <keras.layers.convolutional.Conv2D at 0x1dd796e5b70>,\n",
       " 'batch_normalization_168': <keras.layers.normalization.BatchNormalization at 0x1dd797a4908>,\n",
       " 'activation_168': <keras.layers.core.Activation at 0x1dd79821e80>,\n",
       " 'conv2d_165': <keras.layers.convolutional.Conv2D at 0x1dd795a6a90>,\n",
       " 'conv2d_169': <keras.layers.convolutional.Conv2D at 0x1dd7982cf28>,\n",
       " 'batch_normalization_165': <keras.layers.normalization.BatchNormalization at 0x1dd7950e978>,\n",
       " 'batch_normalization_169': <keras.layers.normalization.BatchNormalization at 0x1dd7986c2b0>,\n",
       " 'activation_165': <keras.layers.core.Activation at 0x1dd794deda0>,\n",
       " 'activation_169': <keras.layers.core.Activation at 0x1dd798b6c18>,\n",
       " 'conv2d_166': <keras.layers.convolutional.Conv2D at 0x1dd7956cfd0>,\n",
       " 'conv2d_170': <keras.layers.convolutional.Conv2D at 0x1dd798fcba8>,\n",
       " 'batch_normalization_166': <keras.layers.normalization.BatchNormalization at 0x1dd79668c18>,\n",
       " 'batch_normalization_170': <keras.layers.normalization.BatchNormalization at 0x1dd7994ae48>,\n",
       " 'activation_166': <keras.layers.core.Activation at 0x1dd795f15c0>,\n",
       " 'activation_170': <keras.layers.core.Activation at 0x1dd799d6b38>,\n",
       " 'max_pooling2d_8': <keras.layers.pooling.MaxPooling2D at 0x1dd799ecf28>,\n",
       " 'mixed8': <keras.layers.merge.Concatenate at 0x1dd79aed5f8>,\n",
       " 'conv2d_175': <keras.layers.convolutional.Conv2D at 0x1dd79e82b00>,\n",
       " 'batch_normalization_175': <keras.layers.normalization.BatchNormalization at 0x1dd79e1d048>,\n",
       " 'activation_175': <keras.layers.core.Activation at 0x1dd79dfd518>,\n",
       " 'conv2d_172': <keras.layers.convolutional.Conv2D at 0x1dd79ab0ba8>,\n",
       " 'conv2d_176': <keras.layers.convolutional.Conv2D at 0x1dd79e43780>,\n",
       " 'batch_normalization_172': <keras.layers.normalization.BatchNormalization at 0x1dd79b36f98>,\n",
       " 'batch_normalization_176': <keras.layers.normalization.BatchNormalization at 0x1dd79e90e48>,\n",
       " 'activation_172': <keras.layers.core.Activation at 0x1dd79b36ef0>,\n",
       " 'activation_176': <keras.layers.core.Activation at 0x1dd79f36128>,\n",
       " 'conv2d_173': <keras.layers.convolutional.Conv2D at 0x1dd79cc5898>,\n",
       " 'conv2d_174': <keras.layers.convolutional.Conv2D at 0x1dd79c630b8>,\n",
       " 'conv2d_177': <keras.layers.convolutional.Conv2D at 0x1dd79f1dc50>,\n",
       " 'conv2d_178': <keras.layers.convolutional.Conv2D at 0x1dd7a04ce10>,\n",
       " 'average_pooling2d_17': <keras.layers.pooling.AveragePooling2D at 0x1dd7a0d3f98>,\n",
       " 'conv2d_171': <keras.layers.convolutional.Conv2D at 0x1dd79aedda0>,\n",
       " 'batch_normalization_173': <keras.layers.normalization.BatchNormalization at 0x1dd79c0f898>,\n",
       " 'batch_normalization_174': <keras.layers.normalization.BatchNormalization at 0x1dd79ceda90>,\n",
       " 'batch_normalization_177': <keras.layers.normalization.BatchNormalization at 0x1dd7a028780>,\n",
       " 'batch_normalization_178': <keras.layers.normalization.BatchNormalization at 0x1dd7a0944a8>,\n",
       " 'conv2d_179': <keras.layers.convolutional.Conv2D at 0x1dd7a1b1668>,\n",
       " 'batch_normalization_171': <keras.layers.normalization.BatchNormalization at 0x1dd79b00c88>,\n",
       " 'activation_173': <keras.layers.core.Activation at 0x1dd79c99c88>,\n",
       " 'activation_174': <keras.layers.core.Activation at 0x1dd79d422e8>,\n",
       " 'activation_177': <keras.layers.core.Activation at 0x1dd79fb52b0>,\n",
       " 'activation_178': <keras.layers.core.Activation at 0x1dd7a07dbe0>,\n",
       " 'batch_normalization_179': <keras.layers.normalization.BatchNormalization at 0x1dd7a159cc0>,\n",
       " 'activation_171': <keras.layers.core.Activation at 0x1dd79a55e48>,\n",
       " 'mixed9_0': <keras.layers.merge.Concatenate at 0x1dd79d0ae10>,\n",
       " 'concatenate_3': <keras.layers.merge.Concatenate at 0x1dd7a12a6d8>,\n",
       " 'activation_179': <keras.layers.core.Activation at 0x1dd7a159dd8>,\n",
       " 'mixed9': <keras.layers.merge.Concatenate at 0x1dd7a1756d8>,\n",
       " 'conv2d_184': <keras.layers.convolutional.Conv2D at 0x1dd7a5652b0>,\n",
       " 'batch_normalization_184': <keras.layers.normalization.BatchNormalization at 0x1dd7a5e1b70>,\n",
       " 'activation_184': <keras.layers.core.Activation at 0x1dd7a67bf28>,\n",
       " 'conv2d_181': <keras.layers.convolutional.Conv2D at 0x1dd7a303be0>,\n",
       " 'conv2d_185': <keras.layers.convolutional.Conv2D at 0x1dd7a238b70>,\n",
       " 'batch_normalization_181': <keras.layers.normalization.BatchNormalization at 0x1dd7a3b76d8>,\n",
       " 'batch_normalization_185': <keras.layers.normalization.BatchNormalization at 0x1dd7a6a4908>,\n",
       " 'activation_181': <keras.layers.core.Activation at 0x1dd7a331b00>,\n",
       " 'activation_185': <keras.layers.core.Activation at 0x1dd7a72dcf8>,\n",
       " 'conv2d_182': <keras.layers.convolutional.Conv2D at 0x1dd7a3db198>,\n",
       " 'conv2d_183': <keras.layers.convolutional.Conv2D at 0x1dd7a4bbe80>,\n",
       " 'conv2d_186': <keras.layers.convolutional.Conv2D at 0x1dd7a6c6f28>,\n",
       " 'conv2d_187': <keras.layers.convolutional.Conv2D at 0x1dd7a95fdd8>,\n",
       " 'average_pooling2d_18': <keras.layers.pooling.AveragePooling2D at 0x1dd7aa3cfd0>,\n",
       " 'conv2d_180': <keras.layers.convolutional.Conv2D at 0x1dd7a28cef0>,\n",
       " 'batch_normalization_182': <keras.layers.normalization.BatchNormalization at 0x1dd7a4977f0>,\n",
       " 'batch_normalization_183': <keras.layers.normalization.BatchNormalization at 0x1dd7a4ead68>,\n",
       " 'batch_normalization_186': <keras.layers.normalization.BatchNormalization at 0x1dd7a76eba8>,\n",
       " 'batch_normalization_187': <keras.layers.normalization.BatchNormalization at 0x1dd7a99d3c8>,\n",
       " 'conv2d_188': <keras.layers.convolutional.Conv2D at 0x1dd7ab469b0>,\n",
       " 'batch_normalization_180': <keras.layers.normalization.BatchNormalization at 0x1dd7a2c3cc0>,\n",
       " 'activation_182': <keras.layers.core.Activation at 0x1dd7a423dd8>,\n",
       " 'activation_183': <keras.layers.core.Activation at 0x1dd7a599e10>,\n",
       " 'activation_186': <keras.layers.core.Activation at 0x1dd7a94e860>,\n",
       " 'activation_187': <keras.layers.core.Activation at 0x1dd7a9e2b00>,\n",
       " 'batch_normalization_188': <keras.layers.normalization.BatchNormalization at 0x1dd7aaa9b00>,\n",
       " 'activation_180': <keras.layers.core.Activation at 0x1dd7a2b2978>,\n",
       " 'mixed9_1': <keras.layers.merge.Concatenate at 0x1dd7a543ef0>,\n",
       " 'concatenate_4': <keras.layers.merge.Concatenate at 0x1dd7aa06f98>,\n",
       " 'activation_188': <keras.layers.core.Activation at 0x1dd7ab03978>,\n",
       " 'mixed10': <keras.layers.merge.Concatenate at 0x1dd7ab54ef0>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the loss to be maximized\n",
    "#create a dcitionary that maps layernames to the layer instances\n",
    "layer_dict = dict([(layer.name,layer) for layer in model.layers])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1112 09:59:00.475097 27828 variables.py:2429] Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "#define loss by adding layer contributions to this scalar variable\n",
    "loss = K.variable(0.)\n",
    "\n",
    "for layer_name in layer_contributions:\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    #retrieve the layer's output\n",
    "    activation = layer_dict[layer_name].output\n",
    "    \n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "    \n",
    "    #add L2 norm of the features of the layer to the loss\n",
    "    loss += coeff * K.sum(K.square(activation[:, 2:-2, 2:-2, :])) / scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv_4:0' shape=(?, ?, ?, 3) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient-ascent process\n",
    "\n",
    "#tensor to hold generated image:the dream\n",
    "dream = model.input\n",
    "\n",
    "#compute the gradients of the dream w.r.t the loss\n",
    "grads = K.gradients(loss, dream)[0]\n",
    "#normalize the gradients\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
    "\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras function to retrieve the value of the loss and gradients, given an input image\n",
    "fetch_loss_and_grads = K.function([dream], [loss,grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value,grad_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for gradient-ascent to run for number of iterations\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('loss value at',i,':',loss_value)\n",
    "        x += step*grad_values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img,size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1, float(size[0])/img.shape[1], float(size[1])/img.shape[2], 1)\n",
    "    return scipy.ndimage.zoom(img,factors,order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    scipy.misc.imsave(fname, pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1,2,0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running gradient ascent over different successive scales\n",
    "import numpy as np\n",
    "\n",
    "step = 0.01\n",
    "num_octave = 3\n",
    "octave_scale = 1.4\n",
    "iterations = 20\n",
    "max_loss = 10.\n",
    "\n",
    "base_image_path = r'C:\\Users\\v-nitbal\\Documents\\DL with Python - Francois Chollet\\CNN for computer vision\\scenery2.jpg'\n",
    "img = preprocess_image(base_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(457, 626), (326, 447), (233, 319)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare a list of shape tuples defining the different scales at which to run gradient ascent \n",
    "original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "successive_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(233, 319), (326, 447), (457, 626)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ascending order of successive_shapes\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "successive_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img = np.copy(img)\n",
    "#resize to the smallest size\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image shape (233, 319)\n",
      "loss value at 0 : 1.7269647\n",
      "loss value at 1 : 2.212258\n",
      "loss value at 2 : 2.8975983\n",
      "loss value at 3 : 3.522655\n",
      "loss value at 4 : 4.2409678\n",
      "loss value at 5 : 4.8925\n",
      "loss value at 6 : 5.5404954\n",
      "loss value at 7 : 6.130284\n",
      "loss value at 8 : 6.7162495\n",
      "loss value at 9 : 7.2278013\n",
      "loss value at 10 : 7.8065653\n",
      "loss value at 11 : 8.334682\n",
      "loss value at 12 : 8.786233\n",
      "loss value at 13 : 9.28951\n",
      "loss value at 14 : 9.757768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\v-nitbal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image shape (326, 447)\n",
      "loss value at 0 : 2.6929464\n",
      "loss value at 1 : 3.9596362\n",
      "loss value at 2 : 5.04655\n",
      "loss value at 3 : 6.0379796\n",
      "loss value at 4 : 6.9275\n",
      "loss value at 5 : 7.727541\n",
      "loss value at 6 : 8.475445\n",
      "loss value at 7 : 9.18998\n",
      "loss value at 8 : 9.868133\n",
      "Processing image shape (457, 626)\n",
      "loss value at 0 : 2.8841429\n",
      "loss value at 1 : 4.121398\n",
      "loss value at 2 : 5.229141\n",
      "loss value at 3 : 6.2501063\n",
      "loss value at 4 : 7.230111\n",
      "loss value at 5 : 8.243117\n",
      "loss value at 6 : 9.309483\n"
     ]
    }
   ],
   "source": [
    "for shape in successive_shapes:\n",
    "    print('Processing image shape',shape)\n",
    "    #scales up the dream image\n",
    "    img = resize_img(img, shape)\n",
    "    \n",
    "    #runs gradient ascent, altering the dream\n",
    "    img = gradient_ascent(img, iterations=iterations, step=step, max_loss=max_loss)\n",
    "    \n",
    "    #scales up smaller version of the original image\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    \n",
    "    #compute high quality version of the original image at this size\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    \n",
    "    #details lost when scaling up\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "    \n",
    "    #reinject lost details into the dream\n",
    "    img += lost_detail\n",
    "    \n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    save_img(img, fname='dream_at_scale_'+str(shape)+'.png')\n",
    "save_img(img, fname='final_dream.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
